---
bibliography: [references.bib]
execute:
  echo: false      # Hide code in all chunks
  warning: false   # Suppress warnings
  eval: true       # Evaluate code
  output: true     # Include the output (e.g., plots, results) in the final document
---
# Data Hazards 

As discussed in more detail below, the Data Hazards initiative was developed a community-driven, shared vocabulary to identify and address risks in data science. This project aims to mitigate risks by helping researchers recognize potential ethical challenges that may not have been initially considered and explore strategies for addressing them. While data scientists are typically trained to solve technical problems, ethical considerations are often overlooked. The Data Hazards project seeks to foster a cultural shift in research by encouraging a wider adoption of ethical considerations within the science community, promoting a more responsible and socially aware approach to scientific work.

As part of my ongoing effort to assess the broader implications of my research, I encountered the Data Hazards Project in 2021. Since then, I have progressively applied the Data Hazards framework to my PhD research. In addition to incorporating Data Hazards into my own research, I have facilitated several workshops on the topic, with details of these sessions available here [Data_Hazards_workshops]. In 2023, I co-organised and co-hosted a one-day symposium focused on Data Hazards, ethics, and reproducibility. Furthermore, I co-authored a chapter on Data Hazards to The Turing Way handbook [REFERENCE]. All of this work culminates with this PhD and the paper I present below, where we extend the application of the Data Hazards framework to the field of neuroscience, exploring how these hazard labels can highlight ethical challenges in computational modelling, specifically focusing on my PhD as a case study. The following paper demonstrates how I have identified risks of my work as well as the efforts taken to mitigate them.

\newpage
\newgeometry{top=0.5in, bottom=1in, left=0.5in, right=0.5in} 

\pagestyle{plain}  

\includepdf[pages=-,pagecommand={\thispagestyle{plain}}]{neuroethics_paper.pdf}

\newpage 
\restoregeometry


The work building up to the paper discussed above was preceeded by a collaboration with the Data Hazards team, where I developed a poster for AI UK 2023 that followed the methodology described in Method 1 of the paper. The poster allowed for reflective discussions with conference attendees, who engaged by selecting Data Hazard labels they believed applied to my PhD project. As shown in @fig-barchart, the labels were chosen in different quantities, with some labels being chosen more often than others.

```{python}
#| label: fig-barchart
#| fig-cap: "Data Hazards labels that may apply to my PhD."
#| fig-pos: 't'

import numpy as np
import matplotlib.pyplot as plt

# The dataset:
data = {'Reinforces existing biases':4, 'High environmental impact':5,
        'Lacks community involvement':4, 'Danger of misuse':5, 'Difficult to understand':6,
        'May cause direct harm':1, 'Lacks informed consent':4}
courses = list(data.keys())
values = list(data.values())
  
fig = plt.figure(figsize = (6, 5))
plt.xticks(rotation=30,ha="right")
 
# Creating the bar plot
plt.bar(courses, values, color ='tab:red',
        width = 0.4)
 
plt.xlabel("Data Hazard Labels")
plt.ylabel("No. of times label was chosen as \n relevant for my PhD project")
plt.title("Data Hazards labels that may apply to my PhD")
plt.show()
```

Interestingly, not all labels were chosen as applicable to my project (Figure 3.6). Only 6 of the 11 current labels were chosen as relevant, with “difficult to understand” being the most prevalent one, chosen by 6 people. High environmental impact and danger of misuse follow in closely with 5 people having chosen these ones. Of course these numbers are small and hold, more than anything, illustrative value as to how and why people may think certain labels apply to a project. Difficult to understand” label was chosen the most, followed by “high environmental impact” and “danger of misuse”. 

conclusion 