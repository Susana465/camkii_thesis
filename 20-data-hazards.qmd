---
bibliography: [references.bib]
---
# Data Hazards 

As discussed in more detail below, the Data Hazards initiative has developed a community-driven, shared vocabulary to identify and address risks in data science. This project aims to mitigate risks in (data) science by helping researchers recognize potential ethical challenges that may not have been initially considered and explore strategies for addressing them. While data scientists are typically trained to solve technical problems, ethical considerations are often overlooked. Second, the project seeks to foster a cultural shift in research by encouraging the wider adoption of ethical reflexivity within the data science community, promoting a more responsible and socially aware approach to scientific work. Before I present the published article where co-authors and I propose the Data Hazards as an ethical framework for neuroscience and in particular think about the Data Hazard Labels apply to this PhD, let me show you the work leading up to it. 

There are 11 data hazards at the moment (Figure 3.1), which include a label description, examples and general safety precautions to showcase how we might go about thinking about these risks (Table REFERENCE). For a full description of the Data Hazard labels, and to avoid repetition, see [SECTION WITH DATA HAZARD LABELS]. There is no prescribed method to apply the Data Hazard labels to one's work,however in Turing Way Chapter we propose four key iterative steps that can be useful; in combination with this, in the published article, we propose two complimentary methods to go about applying Data Hazard labels. The four iterative recommended steps are:

Learn about the labels: familiarise yourself with the Data Hazard labels.
Apply them: decide which Hazard labels are relevant to your project.
Reflect: on what to do differently and what mitigations to make.
Display them: displaying the labels alongside your work can help you to communicate that you’ve thought about these broad ethical issues and how you’d like others to use your work.

As part of my ongoing effort to assess the broader implications of my research, I encountered the Data Hazards Project in 2021. Since then, I have completed a facilitator training workshop and have progressively applied the Data Hazards framework to my PhD research. To illustrate this integration, I presented a poster at the COMBINE and ICSB 2022 conferences [REFERENCES].

In addition to incorporating Data Hazards into my own work, I have facilitated several workshops on the topic, with details on my preparation available here [Data_Hazards_workshops]. In 2023, I co-organised and co-hosted a one-day symposium focused on Data Hazards, ethics, and reproducibility. Furthermore, I contributed to the development of a new chapter on Data Hazards for The Turing Way handbook [REFERENCE]. I also collaborated with the Data Hazards team to develop a poster for AI UK 2023, where I presented my PhD research [FIGURE REFERENCE] and invited conference attendees to discuss which Data Hazard labels they believed were applicable.

This poster was part of an exhibition stand with the Data Hazards Team, at AIUK 2023. When creating this poster, I was able to both do some self-reflection and collaborative reflection, as described below.


{insert paper}

conclusion 