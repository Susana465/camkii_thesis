---
bibliography: [references.bib]
---

# Introduction to computational modelling
The term "computational modelling" serves as an umbrella term, covering different ways of models that are designed to help us understand real-world phenomena.  For simplicity, this PhD defines computational modelling broadly as "the use of computers to simulate and study complex systems through mathematics, physics, and computer science" [as described in REFERENCE fact sheet]. A computational model incorporates numerous variables representing the system under study, with simulations performed by adjusting these variables —either independently or in combination— and observing the outcomes. This PhD specifically employs computational modelling to explore biological systems, focusing on biochemical modelling of dynamic, complex reaction networks that underpin biological processes. 

What this chapter includes: abstract.

## Why use computational modelling to study biological systems?
Modelling aims to describe elements of a system of interest, their states, and their interactions with other elements. A model should be detailed and precise enough to simulate the system's behavior on a computer. Living cells are complex, with biochemical processes organized across various compartments like the extracellular space, cytosol, plasma membrane, and organelles. These processes are multiscale, involving small-scale molecular interactions that lead to emergent, larger-scale cellular behaviors. Understanding these dynamic, multiscale processes requires appropriate mathematical tools to analyze and control the system's behavior, which can help understanding life and disease.

(this is repeated from intro - need to rewrite) _An important aim of modelling is to make clear the current state of knowledge regarding a particular system, by being precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding. Our understanding of experimental observations in any system can be measured by how closely the simulations we create mimic the system's real behavior. Behaviours of computer executable models are at first compared and validated with experimental values. If at this stage inconsistency is found, it means that the assumptions, that represent our knowledge on the system, are at best incomplete, or that the interpretation of the experimental data is wrong. Models that  survive this initial validation can then be used to make predictions to be tested by experiments, as well to explore configurations of the system that are not easy to investigate by _in vitro_ or _in vivo_ experiments. Creating predictive models can give opportunities for unprecedented control over the system. Modelling can provide valuable insights into the workings and general principles of organization of biological systems._

Using computational methods for studying biological mechanisms can offer many advantages, including considerable time and cost-efficient savings. Using computer models allows us to study the specific molecules in question, for example, with the ability of testing minimal requirements of very complex systems by just considering the molecules immediately influencing the phenomenon that is being studied. Of course this comes with the caveat that the whole system dynamics cannot be observed. Nevertheless, useful predictions can come out of these models to combine with wet lab research and a combination of both can be useful for creating predictions about biological phenomena. 

This project looks at biology at the level of protein-protein interactions and dynamics. It takes the view that looking at these dynamics is necessary if we want to understand emergent properties of these interactions. Modelling, simulation, and analysis of simulation outcomes are well positioned for integration into the experimental cycle of cell/molecular biology. Although _in vitro_ and _in vivo_ experiments might still be needed to advance our understanding of biological processes, conducting _in silico_, or computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space. This in turn can mean a reduction of repeated wet-lab experiments, meaning reduced suffering of non-human animals, in accordance with the “Replacement” R of the 3Rs framework @tannenbaum2015Russell. 

### Complexity in systems biology {#sec-compexity-systems-biology}
The computational modelling work of this project sits within something known as complexity science. Complexity science is the study of a systems interacting parts and the emergent behaviours that appear when looking at these interactions; examples of application of complexity science can be predator-prey models, epidemiological modelling of pandemics, protein-protein interaction networks, models of neurons, and more. When applied to biology, complexity science often falls under the banner of Systems Biology. Systems biology refers to the quantitative analysis of dynamic interactions between multiple components within a biological system, with the goal of understanding the system's behaviour as a whole. Systems biology entails the development and application of systems theory principles to study complex biological systems through an iterative process of mathematical modelling, computational simulation, and biological experimentation. It serves as a tool to increase our understanding of biological systems, to develop more directed experiments, and to allow accurate predictions. 

In systems biology, it is helpful to understand and clarify what complexity means also in respect to: 

- **The model: the large number of variables that can determine behaviour.** Some hallmarks of complexity are usually the number of parameters, order of equations and evolution of networks. For example, a protein containing n peptide substrates of kinases can potentially be found in up to 2n distinct phosphorylation states. This feature of protein–protein interactions, which arises because a typical protein involved in cellular regulation contains multiple sites of post-translational modification and multiple binding sites, has been called combinatorial complexity and is a common challenge to our understanding of cellular regulation (REFERENCE Klamt and Stelling, 2002) (REFERENCE Green et al., 2018). This point relates to the explanations given below too. 

- **The natural system: the connectivity and non-linearity of relationships.** In biological systems large numbers of functionally different, and often multifunctional, sets of elements interact selectively and non-linearly to produce complex behaviours. A biological system is not always necessarily equal to the sum of its parts (REFERENCE Nurse, 1997), where functions emerge from the properties of the networks rather than from any specific element. On the contrary, in biological systems, functions rely on a combination of the network and the specific elements involved. CaMKII interaction pathways serve as a good example here too. This protein can be activated, inhibited and degraded by reactions such as phosphorylation and de-phosphorylation, while its targets are selected by the different modification patterns that exist; these are properties that reflect the complexity of the element itself.

- **The technology: the limited precision and accuracy measurements.** When modelling biological systems we encounter more layers of complexity such as, for example, looking at quantitative measures by experimental biologists: for instance, which parameters are available for modelling the system? Which ones do we infer? And in doing so, what are the model parameter sensitivity and initial values sensitivities? The popular measure of complexity for dynamical system is the computational complexity. For example, although a calculated measure in a mathematical model can characterize the amount of information necessary to predict the future state of the machine, it fails to address its meaning in the world of molecular and modular cell biology. 

-	**The methodology: the uncertainty arising from the conceptual framework chosen.** The noise in complexity of the systems increases even further by introducing issues of robustness, noise-resonance and bi-modal behaviour. For example, once we have some outcomes in the model, how can we make sure results are robust and certain?

Understanding how complexity  plays a critical part in th systems studied in this project is key to understand how and why we choose to model these systems. The molecular system this project is investigating encompasses intricate protein-protein interactions. Specifically, we are interested in catalytic interactions that drive post-translational covalent modifications such as enzyme-driven phosphorylation of amino acids in proteins, as well as interactions between proteins that promote the assembly of heterogeneous molecular complexes. These types of interactions are hallmark drivers of combinatorial complexity in cellular systems and biochemical networks. Systems of interacting proteins are inherently complex as the interactions between its constituent proteins usually have the potential to create a vast array of distinct chemical species. This number can far exceed the actual count of proteins or protein interactions within the system itself. When proteins interact, they create unique states that alter the protein’s function, structure, or binding capabilities. Each protein can undergo multiple types of modifications or engage in various site binding interactions, leading to a multitude of distinct protein configurations. This creates a combinatorial complexity, where every modification or binding event adds another layer of potential molecular arrangements. 

Moreover, these distinct molecular species states do not exist in isolation. They are interconnected through an extensive network of reactions, further amplifying the system's complexity. Intricate network of protein–protein interactions is a prominent features of any signal-transduction system @gomperts2009Signal, @hunter2000Signaling. These interactions can occur at multiple levels, including feedback loops, cross-talk between pathways, and spatial-temporal variations. Each reaction acts as a link within a larger network, creating pathways that connect different species. Modelling these networks is therefore particularly complex due to the difficulty in capturing all possible interactions and the uncertainty in the exact nature of these interactions (i.e. not all possible states of a molecular species may be relevant for its functions [REFERENCE]).

#### Combinatorial complexity {.unnumbered}
The magnitude of combinatorial complexity can be exemplified well with the CaMKII holoenzyme studied in this PhD. CaMKII is a multi-subunit protein that can exist in a vast number of possible functional states, depending on the modifications and interactions at each subunit. Each of the individual subunits of CaMKII can have multiple possible states, influenced by factors such as phosphorylation, binding to calmodulin, and interactions with other proteins like NMDARs. 

To understand and quantify CaMKII's combinatorial explosion, lets consider a (non-exhaustive) example where each CaMKII subunit can be found in the following possible states: inactive or active, unphosphorylated at the T286 site or phosphorylated, calmodulin binding site can be free or bound to calmodulin, and NMDAR binding site can be free or bound to CaMKII. This is, the activation flag can be in one of **two** states. The T286 phosphorylation site can also have **two** states. The CaM-binding flag can also be in **two** states, either be bound or unbound. Same goes for the NMDAR binding site which has **two** states. This means that in this example there is a total of 16 possible state combinations that a _single subunit_ can exhibit.

Next, we consider the rotational symmetry of the holoenzyme. Due to this symmetry, certain subunit configurations are equivalent because rotating the arrangement of subunits does not result in a distinct new state. Rather than treating each subunit’s state as independent in every possible configuration, rotational symmetry allows us to group identical states that can be reached by rotating the holoenzyme, thereby reducing the total number of unique configurations. To account for this rotational symmetry, we use a combinatorial concept known as necklace numbers, which helps calculate the number of distinct configurations of subunits when rotational symmetry is present. By leveraging necklace numbers, we can more efficiently calculate the number of unique arrangements of CaMKII subunits, as it ensures that rotations of identical configurations are not counted multiple times. This approach allows for a more manageable quantification of the system’s complexity. The formula for necklace numbers is shown in @eq:necklace .

$$
N(n, a) = \frac{1}{n} \sum_{i=1}^{v(n)} \phi(d_i) a^{n/d_i}
$$ {#eq:necklace}

Where \( n \) represents the number of subunits (or beads on a necklace), \( a \) is the number of possible states per subunit, and \( \phi(d_i) \) is Euler’s totient function, which helps account for symmetries by considering the divisors of \( n \). 

Thus, for a CaMKII ring with 6 subunits (a=6) with each one having 16 possible states (a=16), the possible number of state combinations would be: 2,796,976. This number of possible states is only estimated for one of the hexamer rings of a CaMKII dodecamer (which has 2 rings of 6 subunits). This example hopefully serves to illustrate how the combinatorial explosion of CaMKII's possible states makes it practically impossible to explicitly enumerate or efficiently evaluate all possible configurations using conventional mass action-based methods. In fact, previous studies have suggested that a CaMKII dodecamer could have as many as $10^{20}$ possible states (see appendix S1 for [@pharris2019Multistate]). Moreover, the fact that the potential states of CaMKII vastly outnumber the actual CaMKII molecules in a dendritic spine, suggests that not all states occur with the same frequency and therefore not all mathematically calculated states are equally biologically relevant. 

This highlights the challenges of modelling systems that involve combinatorial complexity. The complexity arises from the biological system itself but it also presents practical difficulties when it comes to modelling the system at hand. The complexity impacts both the process of writing the model (for example deciding which states to include) and the computational demands of running it, particularly in terms of time and resources. When it becomes computationally infeasible to enumerate or simulate all state and network possibilities, the model may become intractable, requiring excessive time and/or resources to compute and analyse. Here, rule-based modelling offers a powerful solution: rather than accounting for every possible state, it allows us to focus on the biologically significant states and enables the model to reveal emergent behaviours through rule-based interactions.

### Rule based modelling 
The challenges posed by combinatorial complexity motivate the adoption of a rule based modelling (RBM) approach for simulating cell signalling systems. RBM can help with combinatorial complexity by using a set of logical rules to describe how molecules interact with each other. In RBM, the system is modelled by specifying the reactions (or rules) that describe how molecules interact and change. Instead of listing every individual interaction or molecular species explicitly, rules are used to represent how molecules bind, modify, and transform. These rules are applied to sets of molecules that can be in different states or configurations, and the overall dynamics of the system emerge from the repeated application of these rules. This method allows for computationally efficient models and can scale to handle large and complex systems.

RBM represents molecules as structured objects, and then rules are used to define the interactions of these molecules. In other words, molecular interactions are modelled as rules for transforming the attributes of these objects. In our approach, we employ rule-based modelling using the BioNetGen Language (BNGL), though other tools like Kappa and PySB (and more [REFERENCES]) are also available. Different approaches to RBM are used depending on one's objectives and modelling focus [REFERENCES]. BNGL provides a language that is tailored towards modelling biochemical networks with domain-specific requirements, allowing for the detailed specification of molecules and their binding domains, which is particularly useful for studying protein post-translational modifications, for example autophosphorylation of CaMKII. Moreover, the ability to model site-specific details of protein-protein interactions allows these dynamics to be captured systematically, thereby addressing nomenclature challenges and improving the reusability of the models. Additionally, BNGL supports the inclusion of cellular compartments through its compartmental extension (cBNGL), enabling explicit modelling of the compartmental organization of the cell and it’s effects on system dynamics. This way, we can introduce localization attributes for molecular species, as well as appropriate volumetric scaling of reaction rates. Moreover, BNGL has been integrated with MCell4, a simulation software usedin this project (as detailed in SECTION REFERENCE), via pyBNGL, a Python library. This integration enables BNGL models to be executed as network-free simulations and spatially resolved, allowing for more nuanced and detailed analysis, which we will discuss in more detail later on (REFERENCE SECTION).

In summary, these capabilities make BNGL an ideal language for encoding our models, offering key advantages, BNGL can:

- Facilitate the modelling of domain-specific modifications, which is crucial for understanding site-specific binding and post-translational behaviours in molecules such as CaMKII and NMDA receptors within the postsynaptic density of neuronal dendrites.

- Allow for these interactions to be studied through time and space (when combined with MCell4). This means that we can not only observe site-specific interactions but also track how these interactions evolve over time and within a cellular volume. For instance, we can investigate whether CaMKII is more likely to be phosphorylated near the postsynaptic density or at a distance from it.

More generally, BNGL rule based modelling also helps to manage complexity in several ways: through network-free modelling, we can avoid the combinatorial explosion associated with enumerating an entire network, which is often intractably complex. Additionally, its rule-based approach enables us to bypass the need to specify all possible states. This is facilitated by a "don't care, don't write" principle, which we will elaborate on in the following section.

Importantly, rules in RBM are primarily based on experimental observations and they determine when an implicitly defined reaction can happen. For any given iteration, only the states that matter for the execution of a particular reaction (or rule) are explicitly declared. States that do not matter to a particular rule can be omitted, this is the powerful idea of “don’t care, don’t write”. For instance, lets consider a reaction rule where a CaMKII subunit binds to a CaM molecule [@fig-bngl-rbm-example]. 

![CaMKII binding to CaM example of don't care, don't write in bionetgen rule based modelling. The CaMKII subunit is depicted with several possible states, each defined by different flags. The open flag determines whether the subunit is in a closed (0) or open (1) state. The T286 and T306 flags represent the phosphorylation states, where a value of 0 indicates the subunit is unphosphorylated, and "P" indicates phosphorylation at those specific sites. The cam flag refers to a binding site for CaM, which can either be bound or unbound, depending on whether CaM is attached to the subunit. Similarly, the nmdar flag represents another binding site for the NMDA receptor, which can also be in a bound or unbound state. The cam and nmdar flags represent binding events that can occur or not, depending on whether CaM or NMDA receptors are bound to the subunit. In this case, for the reaction to proceed, CaMKIII needs to be open, unphosphorylayed at T306, and unbound from any calmodulin molecules, for calmodulin to bind. The requirements for CaM to bind to CaMKII are that it is in a state of being bound to four calcium, and its camkii binding site is free. When these conditions are met, regardless of any other states, the reaction will occur. As a result a molecular complex will form, where CaMKII and CaM are bound through their respective binding sites, represented with a “!1” link notation. The drawings in this figure are abstractions designed to simplify the understanding of the molecular interactions. They do not depict each individual binding site, as the focus here is on illustrating the rule scripting and the formation of molecular complexes.](30-modelling-figures\camkii_cam_bngl_example.PNG){#fig-bngl-rbm-example}

In this example, we don't specify the state of T286 or whether CaMKII is bound to NMDARs or not. The reaction rule only specifies the states that are relevant for said reaction, and the rest is left unspecified. This dramatically reduces the number of reactions that need to be written, which also helps to alleviate potential computational challenges posed by combinatorial complexity [REFERENCE].


--
maybe use for linking with mcell A rule-based model is capable of comprehensively accounting for the consequences of protein—protein interactions, including all possible phosphoforms of a protein and the full spectrum of possible protein complexes implied by a given set of interactions. Such a model is specified using BNGL in a BioNetGen input file, which may also contain directions for processing the model specification
--

_(From Pharris paper) To characterize the spatiotemporal regulation of CaMKII, experimental studies are increasingly complemented by computational models [15, 17, 25–28]. Computational models of Ca2+-dependent signaling implicate competition, binding kinetics, feedback loops, and spatial effects in regulating enzyme activation [7, 12, 24, 29, 30]. However, fully characterizing these and other mechanisms of CaMKII regulation is impeded by the challenge of accurately portraying the CaMKII holoenzyme. As described by previous work, combinatorial explosion can occur when modeling CaMKII (and similar biomolecules) activation because the protein exhibits a large number of functionally significant and not necessarily inter-dependent states [24, 26, 31–33]. The large number of possible states of CaMKII can neither be explicitly specified nor efficiently evaluated with conventional mass action-based methods. Indeed, for just one CaMKII hexamer ring, we estimate a state space of ~32 billion states, and for the full dodecamer approximately 1020 possible states (See Text A in S1 Appendix). The numbers of possible CaMKII states far exceeds the number of CaMKII molecules in a dendritic spine, suggesting that some states rarely occur and thus likely contribute little to protein function. Previous models leverage this observation to reduce the model state space and provide valuable insight to CaMKII binding and autophosphorylation dynamics [24, 33–36]. However, for CaMKII it remains unclear which states functionally participate in synaptic plasticity. Reduced models can inadvertently obscure key mechanisms regulating CaMKII activation and autophosphorylation. To elucidate complex regulatory mechanisms, it may be necessary for models to provide for all possible states ab initio._

wHAT STORY DO I WANT TO TELL WITH RBM?

combinatorial complexity 
domai specific modelling and why this is relevant and useful, and especially for our type of modelling
rules are useful for these things. 
rules are also useful for not having to specify all states from a chemical network (and this helps with combinatorial complexity too). how does this thing of not having to specify all states works (there was a paper I have to find again that explained this well by faeder et al., maybes its in zotero)
what the rules actually look like. 
queue in bngl

and then queue in bionetgen python and mcell combinatio software possibilities? where do I add mcell?

Cell signalling systems involve numerous interacting biomolecules, like proteins, which are made up of various functional components (such as binding domains, motifs, and phosphorylation sites). This complexity allows biomolecules to engage in multiple interaction types, leading to a rapid, combinatorial increase in the possible states of complexes and modifications. Accurately capturing all the potential effects of these interactions requires extremely large reaction networks, which traditional approaches, such as ODEs, struggle with because they require each reaction in the network to be explicitly defined. Rule based modelling can help with this problem by representation of interactions in terms of local rules. In Rule-Based Modelling (RBM), the network structure is defined indirectly, allowing for concise and efficient model representation. 

RBM can help with combinatorial complexity by using a set of logical rules to describe how molecules interact with each other. Rather than enumerating each individual interaction or molecular species explicitly, RBM models use rules to represent the binding, modification, and transformation of molecular entities in a much more abstract and flexible manner. These rules can account for a wide variety of interactions, including those influenced by post-translational modifications, conformational changes, or the spatial arrangement of molecules. In RBM, the system is modelled by specifying the reactions (or rules) that describe how molecules interact and change. These rules are applied to sets of molecules that can be in different states or configurations, and the overall dynamics of the system emerge from the repeated application of these rules. The result is a dynamic model where the changes in the system over time are driven by the application of these rules, which is computationally efficient and scalable to large and complex systems.


#### BioNetGen: A Tool for Rule-Based Modeling {.unnumbered}

BioNetGen is a powerful and widely used tool for performing Rule-Based Modeling of biochemical networks, particularly in the context of signaling systems and protein–protein interactions. BioNetGen uses a language called BNGL (BioNetGen Language) to define molecular species and the rules that govern their interactions. (i THINK THIS IS TOO GENERAL BUT HERE IT GOES) The key feature of BioNetGen is that it allows researchers to describe the interactions between proteins and other molecules in a high-level, abstract form, without the need to manually enumerate every possible molecular species or state. Instead, BNGL allows users to define generalized rules that specify how molecular entities can interact—such as binding, phosphorylation, or degradation—along with the conditions under which these interactions occur (e.g., certain modifications or specific conformations).

--

Moreover, BioNetGen can be integrated with other modeling tools, such as those for parameter estimation or network analysis, and can be used in combination with experimental data to validate and refine models. Its ability to simulate the dynamics of protein–protein interaction networks in a computationally efficient manner has made it an indispensable tool in computational biology, systems biology, and bioinformatics research.



There are three main things that are important here: space, time and structure of molecules (?) -> yes thats why RBM CAN BE HELPFUL. 

the way compratments work in this kind of modelling - will need a methods section that is more specific than this one i think.

what goes in a model and what comes out 


## How do we model biochemical systems networks?

Biological and chemical systems can be described by networks of chemical reactions; in other words, the cascades of interactions between CaMKII and NMDARs with other molecules can be understood as a network of chemical reactions. Computational models of these reaction networks can be used to elucidate their dynamics. Reaction-based models are formalized as sets of reactions that describe the given system in terms of mechanistic interactions between the species of interest. This is, biochemical networks are a set of chemical species that can be converted into each other through chemical reactions. The focus of biochemical network models is usually on the levels of the chemical species and this usually requires explicit mathematical expressions for the velocity at which the reactions proceed (reaction rates). Once the kinetics have been specified, these systems can be used directly to construct full dynamic simulations of the system behaviour on a computer. Biochemical network models allow us to gather insight by simulating chemical interactions over time; we can observe changes in species levels, visualise stable states within the system, and look for potential direct or indirect causal relationships between the species being studied. Importantly, the modellers can modify any of these parameters to test how such changes impact the model’s results.

Biological systems can be simulated in different ways using different algorithms depending on the assumptions made about the underlying kinetics, as we will see below; and different formalisms are usually applied to describe the dynamics of these biochemical systems. The kinetics of chemical reactions vary based on the timing of molecular interactions, with reactions unfolding over a timescale determined by the microscopic mechanics involved. Molecular collisions occur randomly inside cells, and are influenced by factors like thermal motion and diffusion. This randomness means that the number of molecules of a particular species fluctuates as a random variable. However, when we observe large-scale, or macroscopic, quantities —such as the concentration of a substance over time— the outcomes tend to be consistent and predictable. This predictable trend enables us to develop rate laws, mathematical expressions that describe how the concentration of molecules changes over time. Rate laws are foundational to deterministic modelling, as they assume that, given a specific starting point (initial conditions), the progression of a chemical process is fixed or "predestined." Deterministic models thus allow scientists to predict the time evolution of chemical concentrations with high accuracy, even if the underlying molecular interactions remain random on a microscopic scale. Deterministic models work well where molecular species exists in vast quantities. However, as systems decrease in scale -such as in the confined environment of a cell's cytosol- random fluctuations in molecular populations become significant, making experimental results less reproducible and measurements more variable. Unlike deterministic models, which assume smooth, predictable changes, stochastic models accommodate the random fluctuations in molecule numbers that can significantly impact reaction outcomes in confined environments. Lets briefly examine the reasons why each of these approaches may be employed for distinct purposes:

### Deterministic and stochastic modelling {.unnumbered}

**Deterministic modelling:**
Deterministic approaches to chemical kinetics are often used to characterize time evolutions of chemical reactions in large systems. A popular representation for these models is to use ordinary differential equations (ODEs) to describe the change in the concentrations of chemical species. Running the same set of parameters using deterministic simulations will produce the same results each time by solving these ODEs. Such descriptions are appropriate when the number of particles involved in the biochemical network is large enough to be able to consider continuous concentrations and when spatial effects are negligible, i.e. well-mixed environment is assumed and space has no effect on reactions. In ODE-based models, each chemical species in the network is represented by an ODE that describes the rate of change of that species along time. Therefore, ODE models of biochemical processes are useful and accurate in the high-concentration limit, but often fail to capture stochastic cellular dynamics accurately because the deterministic continuous formulation assumes spatial homogeneity and continuous molecular concentrations.

These ODE models can be used to simulate the dynamics of the concentrations of the chemical species along time given their initial values. This is achieved by numerical integration of the system of ODE which can be carried out with well-established algorithms (e.g. simple forward Euler method). They are also useful to find, for example, steady states of the system, which are conditions when the concentrations of the chemical species do not change @maly2009Introduction.

**Stochastic modelling:**
Another representation that is useful in systems biology is stochastic simulations, which use probability distribution functions to estimate when single reaction events happen and therefore track the number of particles of the chemical species. As a general rule, stochastic simulations are preferred where the numbers of particles of a chemical species is small; the ODE approach is required when the number of particles is large because the stochastic approach might be computationally intractable. When the assumption of continuous concentration fails due to small-scale cellular environment with limited reactant populations, ODE representation also fails. It is here when stochastic simulations are useful. 

It is important to stress that one simulation run according to stochastic approaches is only one realization of a probabilistic representation, and thus provides limited amount of information on its own. When running stochastic simulations, it is very important that they are repeated for a sufficient number of times in order to reveal the entire range of behaviour presented by such a system (i.e., to estimate a distribution for each chemical species and its dynamic evolution). 

NEED TO DO: Example jupyter notebook. Attach figures and link. 

## Reaction Rates (probably not here but later on more specifically)
MCell and BioNetGen use different units for bimolecular kinetic rates. In MCell, a volume-volume reaction (reaction between two molecules that are free to diffuse in 3D space) is M-1*s-1where M is the molar concentration (number of moles per liter). In BioNetGen, the user is not constricted to a specific unit but a usual unit is N-1*s-1where N is a number of molecules per compartment and the default compartment volume if a compartment is not specified is 1fl (= 1 um3).

To convert from BioNetGen to MCell units, one needs to multiply the BioNetGen rate by NA * V where NA is Avogardro’s constant and V is volume of the compartment is liters as derived here:

1/M = 1/(#moles/V) = 1/( (N/NA)/V) = NA * V * 1/N

The unimolecular reaction rates in MCell and BioNetGen both use unit s-1.

### Software used in this PhD {.unnumbered} - MIGHT need to be a chapter in itself


In summary, some of the main reasons for using modelling are:

1.	Biological systems are complex and multiscale, models can help us to integrate experimental data, facilitating theoretical hypotheses, and addressing what if questions.

2.	Models aim to make clear the current state of knowledge regarding a particular system, by attempting to be precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding.

3.	Related to point one, models then serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists.

4.	Computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space, enabling more cost, time-effective and waste-free research, as well as more ethical research too as we reduce animal suffering through reduction of animal research.
