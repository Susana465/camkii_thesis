---
bibliography: [references.bib]
---

## Why use Computational Modelling to study biological systems?

Modelling is an attempt to describe an understanding of the elements of a system of interest, their states, and their interactions with other elements. The model should be sufficiently detailed and precise so that it can in  principle be used to simulate the behaviour of the system on a computer. Living cells are complex structures where biomolecules and biochemical processes are spatially organized and span the extracellular space, cytosol, plasma membrane and subcellular organelles. These biochemical processes are inherently multiscale, since they are based on molecular interactions on a small scale which then lead to emergent behaviours of cells on a larger scale. Due to the dynamic nature of biochemical processes on different temporal and spatial scales, appropriate mathematical tools are required to understand the underlying dynamics and to analyse the mechanisms that control the system’s behaviour. In fact, understanding how cellular function and design then leads to function is essential for understanding life and disease.

An important point to mention with these types of investigations, where we look at health and disease in a more “detached-from-patient” manner, is whether results obtained may contribute further to an oppressive bias. Medicine tends to aim to “fix” individuals, hence further perpetuating an ableist medical model of disability. Disability is commonly viewed as a problem that exists in a person’s body and requires medical treatment; however, there is a social model of disability which, by contrast, distinguishes between impairment and disability, identifying the latter as a disadvantage that stems from a lack of fit between a body and its social environment. This will become important when discussing the data hazards in research. 

Mathematical and computational frameworks for modelling and simulating biological process at the system level are faced with the main feature of such systems: the complexity. Complex behaviour occurs when many interactions at the local scale collectively lead to unpredictable larger-scale outcomes, as we talked about in the “Complexity Science” section before. Additionally, experimental studies are often unable to produce a sufficient amount of data to support theoretical interpretations; on the other hand, due to data insufficiency, theoretical research cannot provide substantial guidance and insights for experimentation. Therefore computational modelling takes a more important role in biology by integrating experimental data, facilitating theoretical hypotheses, and addressing what if questions.

In fact, an important aim of modelling is to make clear the current state of knowledge regarding a particular system, by attempting to be precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding. Our understanding of the experimental observations of any system can be measured by the extent to which a simulation we create, mimics the real behaviour of that system. Behaviours of computer executable models are at first compared and validated with experimental values. If at this stage inconsistency is found, it means that the assumptions, that represent our knowledge on the system, are at best incomplete, or that the interpretation of the experimental data is wrong. Models that  survive this initial validation can then be used to make predictions to be tested by experiments, as well to explore configurations of the system that are not easy to investigate by in vitro or in vivo experiments.  Creating predictive models can give opportunities for unprecedented control over the system. Modelling can provide valuable insights into the workings and general principles of organization of biological systems.

Using computational methods for studying biological mechanisms can offer many advantages, including considerable time and cost-efficient savings. Using computer models allows us to study the specific molecules in question, for example, with the ability of simplify very complex systems by just considering the molecules immediately influencing the phenomenon that is being studied. Of course this comes with the caveat that the whole system dynamics is not being taken into account. Nevertheless, useful predictions can come out of these models to combine with wet lab research. Computer models then, are useful for creating predictions about biological phenomena. 

In biological settings, traditionally -although not always-, scientists make a hypothesis before doing the experiments, and this therefore helps guide their research for an unexplained phenomenon. So, for example, a hypothesis could be “Abolishing of CaMKII and NMDAR binding increases the amount of phosphorylated CaMKII in the PSD”. However, here we do not set a specific set of hypotheses; instead, the models created serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists. This project looks at biology at the level of protein-protein interactions and dynamics. It takes the view that looking at these dynamics is necessary if we want to understand emergent properties of these interactions. Therefore, modelling, simulation, and analysis of simulation outcomes are perfectly positioned for integration into the experimental cycle of cell/molecular biology. Although in-vitro and in-vivo experiments might still be needed to advance our understanding of biological processes, conducting in silico, or computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space. This in turn can mean a reduction of repeated wet-lab experiments, meaning reduced suffering of non-human animals, in accordance with the “Replacement” R of the 3Rs framework @tannenbaum2015Russell. 

Likewise, much of in-vitro research uses animal products (for example, for growing cell lines), and this uses an enormous amount of toxic chemicals as well as a huge amount of single-use plastic that cannot be recycled because of biohazard regulations. Designing better experiments, commencing from computational models, has the potential to remove waste of experiments that “won’t work” and won’t be published, which was suggested to be 85% of what a researcher produces @glasziou201685. 

In summary, some of the main reasons for using modelling are:

1.	Biological systems are complex and multiscale, models can help us to integrate experimental data, facilitating theoretical hypotheses, and addressing what if questions.

2.	Models aim to make clear the current state of knowledge regarding a particular system, by attempting to be precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding.

3.	Related to point one, models then serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists.

4.	Computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space, enabling more cost, time-effective and waste-free research, as well as more ethical research too as we reduce animal suffering through reduction of animal research.

## How do we model biochemical systems networks?
As we saw in the background section, key processes in biological and chemical systems are described by networks of chemical reactions; i.e., all the cascades of interactions between CaMKII with other molecules can be understood as a network of chemical reactions. And, as mentioned above, computational models of these reaction networks can be used to elucidate their dynamics. 

Reaction-based models are formalized as sets of reactions that describe the given system in terms of mechanistic interactions between the species of interest. This is, biochemical networks are a set of chemical species that can be converted into each other through chemical reactions. The focus of biochemical network models is usually on the levels of the chemical species and this usually requires explicit mathematical expressions for the velocity at which the reactions proceed. Biological systems can be simulated in different ways using different algorithms depending on the assumptions made about the underlying kinetics. Once the kinetics have been specified, these systems can be used directly to construct full dynamic simulations of the system behaviour on a computer.

###  What are deterministic modelling and stochastic modelling?

**Deterministic modelling:**
Deterministic approaches to chemical kinetics are often used to characterize time evolutions of chemical reactions in large systems. A popular representation for these models is to use ordinary differential equations (ODEs) to describe the change in the concentrations of chemical species. Such descriptions are appropriate when the number of particles involved in the biochemical network is large enough to be able to consider continuous concentrations and when spatial effects are negligible, i.e. well-mixed environment is assumed and space has no effect on reactions. In ODE-based models, each chemical species in the network is represented by an ODE that describes the rate of change of that species along time. Therefore, ODE models of biochemical processes are useful and accurate in the high-concentration limit, but often fail to capture stochastic cellular dynamics accurately because the deterministic continuous formulation assumes spatial homogeneity and continuous biomolecule concentrations.

These ODE models can be used to simulate the dynamics of the concentrations of the chemical species along time given their initial values. This is achieved by numerical integration of the system of ODE which can be carried out with well-established algorithms (e.g. simple forward Euler method). They are also useful to find, for example, steady states of the system, which are conditions when the concentrations of the chemical species do not change @maly2009Introduction.

**Stochastic modelling:**
Another representation that is useful in systems biology is stochastic simulations, which use probability distribution functions to estimate when single reaction events happen and therefore track the number of particles of the chemical species. As a general rule, stochastic simulations are preferred where the numbers of particles of a chemical species is small; the ODE approach is required when the number of particles is large because the stochastic approach might be computationally intractable. When the assumption of continuous concentration fails due to small-scale cellular environment with limited reactant populations, ODE representation also fails. It is here when stochastic simulations are useful. 

[//]: <> (This section about CMEs might delete, not done these references on purpose as need to revisit/reread) 

Chemical stochastic systems are usually represented by a chemical master equation (CME) that describes the time evolution of the probability distribution of discrete molecule quantities, i.e. the CME describes temporal evolution of the probability density function (PDF) for states of a chemical system. PDFs are used to describe the timing of reaction events. This evolution of probability is a continuous time Markov chain, of which any possible realizations can be generated through the Monte Carlo sampling methods. The most famous of these methods for coupled chemical reactions is the stochastic simulation algorithm (SSA) of Gillespie. The theoretical derivation of this method can be found in (Gillespie, 1976)(Gillespie, 1977) as well as a more recent review (Gillespie, 2007).

It is important to stress that one simulation run according to stochastic approaches is only one realization of a probabilistic representation, and thus provides limited amount of information on its own. When running stochastic simulations, it is very important that they are repeated for a sufficient number of times in order to reveal the entire range of behaviour presented by such a system (i.e., to estimate a distribution for each chemical species and its dynamic evolution). An example of what these model runs can look like are shown in Figure 8.

[INSERT FIGURE 8]