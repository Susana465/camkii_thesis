---
bibliography: [references.bib]
---

## Why use Computational Modelling to study biological systems?

Modelling aims to describe elements of a system of interest, their states, and their interactions with other elements. A model should be detailed and precise enough to simulate the system's behavior on a computer. Living cells are complex, with biochemical processes organized across various compartments like the extracellular space, cytosol, plasma membrane, and organelles. These processes are multiscale, involving small-scale molecular interactions that lead to emergent, larger-scale cellular behaviors. Understanding these dynamic, multiscale processes requires appropriate mathematical tools to analyze and control the system's behavior, which is crucial for understanding life and disease.

An important concern with these investigations, which view health and disease in a more "detached-from-patient" way, is whether the results could reinforce oppressive biases.Medicine tends to aim to “fix” individuals, hence further perpetuating an ableist medical model of disability. Disability is commonly viewed as a problem that exists in a person’s body and requires medical treatment; however, there is a social model of disability which, by contrast, distinguishes between impairment and disability, identifying the latter as a disadvantage that stems from a lack of fit between a body and its social environment. This will become important when discussing the data hazards that apply to this research. 

An important aim of modelling is to make clear the current state of knowledge regarding a particular system, by being precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding. Our understanding of experimental observations in any system can be measured by how closely the simulations we create mimic the system's real behavior. Behaviours of computer executable models are at first compared and validated with experimental values. If at this stage inconsistency is found, it means that the assumptions, that represent our knowledge on the system, are at best incomplete, or that the interpretation of the experimental data is wrong. Models that  survive this initial validation can then be used to make predictions to be tested by experiments, as well to explore configurations of the system that are not easy to investigate by _in vitro_ or _in vivo_ experiments.  Creating predictive models can give opportunities for unprecedented control over the system. Modelling can provide valuable insights into the workings and general principles of organization of biological systems.

Using computational methods for studying biological mechanisms can offer many advantages, including considerable time and cost-efficient savings. Using computer models allows us to study the specific molecules in question, for example, with the ability of simplify very complex systems by just considering the molecules immediately influencing the phenomenon that is being studied. Of course this comes with the caveat that the whole system dynamics is not being taken into account. Nevertheless, useful predictions can come out of these models to combine with wet lab research. Computer models then, are useful for creating predictions about biological phenomena. 

In biological settings, traditionally -although not always-, scientists make a hypothesis before doing the experiments, and this therefore helps guide their research for an unexplained phenomenon. So, for example, a hypothesis could be “Abolishing of CaMKII and NMDAR binding increases the amount of phosphorylated CaMKII in the PSD”. However, here we do not set a specific set of hypotheses; instead, the models created serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists. This project looks at biology at the level of protein-protein interactions and dynamics. It takes the view that looking at these dynamics is necessary if we want to understand emergent properties of these interactions. Therefore, modelling, simulation, and analysis of simulation outcomes are perfectly positioned for integration into the experimental cycle of cell/molecular biology. Although in-vitro and in-vivo experiments might still be needed to advance our understanding of biological processes, conducting in silico, or computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space. This in turn can mean a reduction of repeated wet-lab experiments, meaning reduced suffering of non-human animals, in accordance with the “Replacement” R of the 3Rs framework @tannenbaum2015Russell. 

Likewise, much of in-vitro research uses animal products (for example, for growing cell lines), and this uses an enormous amount of toxic chemicals as well as a huge amount of single-use plastic that cannot be recycled because of biohazard regulations. Designing better experiments, commencing from computational models, has the potential to remove waste of experiments that “won’t work” and won’t be published, which was suggested to be 85% of what a researcher produces @glasziou201685. 

In summary, some of the main reasons for using modelling are:

1.	Biological systems are complex and multiscale, models can help us to integrate experimental data, facilitating theoretical hypotheses, and addressing what if questions.

2.	Models aim to make clear the current state of knowledge regarding a particular system, by attempting to be precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding.

3.	Related to point one, models then serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists.

4.	Computer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space, enabling more cost, time-effective and waste-free research, as well as more ethical research too as we reduce animal suffering through reduction of animal research.

## How do we model biochemical systems networks?
As we saw in the background section, key processes in biological and chemical systems are described by networks of chemical reactions; i.e., all the cascades of interactions between CaMKII with other molecules can be understood as a network of chemical reactions. And, as mentioned above, computational models of these reaction networks can be used to elucidate their dynamics. 

Reaction-based models are formalized as sets of reactions that describe the given system in terms of mechanistic interactions between the species of interest. This is, biochemical networks are a set of chemical species that can be converted into each other through chemical reactions. The focus of biochemical network models is usually on the levels of the chemical species and this usually requires explicit mathematical expressions for the velocity at which the reactions proceed. Biological systems can be simulated in different ways using different algorithms depending on the assumptions made about the underlying kinetics. Once the kinetics have been specified, these systems can be used directly to construct full dynamic simulations of the system behaviour on a computer.

###  What are deterministic modelling and stochastic modelling?

**Deterministic modelling:**
Deterministic approaches to chemical kinetics are often used to characterize time evolutions of chemical reactions in large systems. A popular representation for these models is to use ordinary differential equations (ODEs) to describe the change in the concentrations of chemical species. Such descriptions are appropriate when the number of particles involved in the biochemical network is large enough to be able to consider continuous concentrations and when spatial effects are negligible, i.e. well-mixed environment is assumed and space has no effect on reactions. In ODE-based models, each chemical species in the network is represented by an ODE that describes the rate of change of that species along time. Therefore, ODE models of biochemical processes are useful and accurate in the high-concentration limit, but often fail to capture stochastic cellular dynamics accurately because the deterministic continuous formulation assumes spatial homogeneity and continuous biomolecule concentrations.

These ODE models can be used to simulate the dynamics of the concentrations of the chemical species along time given their initial values. This is achieved by numerical integration of the system of ODE which can be carried out with well-established algorithms (e.g. simple forward Euler method). They are also useful to find, for example, steady states of the system, which are conditions when the concentrations of the chemical species do not change @maly2009Introduction.

**Stochastic modelling:**
Another representation that is useful in systems biology is stochastic simulations, which use probability distribution functions to estimate when single reaction events happen and therefore track the number of particles of the chemical species. As a general rule, stochastic simulations are preferred where the numbers of particles of a chemical species is small; the ODE approach is required when the number of particles is large because the stochastic approach might be computationally intractable. When the assumption of continuous concentration fails due to small-scale cellular environment with limited reactant populations, ODE representation also fails. It is here when stochastic simulations are useful. 

[//]: <> (This section about CMEs might delete, not done these references on purpose as need to revisit/reread) 

Chemical stochastic systems are usually represented by a chemical master equation (CME) that describes the time evolution of the probability distribution of discrete molecule quantities, i.e. the CME describes temporal evolution of the probability density function (PDF) for states of a chemical system. PDFs are used to describe the timing of reaction events. This evolution of probability is a continuous time Markov chain, of which any possible realizations can be generated through the Monte Carlo sampling methods. The most famous of these methods for coupled chemical reactions is the stochastic simulation algorithm (SSA) of Gillespie. The theoretical derivation of this method can be found in (Gillespie, 1976)(Gillespie, 1977) as well as a more recent review (Gillespie, 2007).

It is important to stress that one simulation run according to stochastic approaches is only one realization of a probabilistic representation, and thus provides limited amount of information on its own. When running stochastic simulations, it is very important that they are repeated for a sufficient number of times in order to reveal the entire range of behaviour presented by such a system (i.e., to estimate a distribution for each chemical species and its dynamic evolution). An example of what these model runs can look like are shown in Figure 8.

[INSERT FIGURE 8]