# Validating model behaviour {#sec-validating-model}
Model validation is essential to ensure that computational simulations reliably reflect underlying biological mechanisms. In this work, the validation involved modular development of the model, comparison with experimental data, and assessment of both qualitative and quantitative accuracy. Each aspect of the model was tested in isolation before integration, and several complementary strategies were employed to evaluate the accuracy, robustness, and predictive capabilities of the system.

In order to validate model behaviour, it was constructed in a modular fashion, with each reaction or set of reactions added sequentially and tested independently. Modular testing is a key strategy in model validation that, in this case, involved building the model in discrete, self-contained sets of reaction rules. 

Each reaction rule was added one by one and tested to see if it reproduced biologically relevant results. By structuring the model in this way, it becomes possible to test and validate individual components independently before integrating them into the full system. This modular approach ensures that the model is built gradually, allowing for careful validation of each new set of reactions before proceeding to more complex processes. This stepwise approach minimises the risk of introducing compounded errors when combining multiple reactions or pathways.

For example, I initially incorporated reactions involving calcium binding to calmodulin and validated this by comparing its output against a previously developed and validated model described in [REFERENCE]. This comparison served as an internal benchmark, as the original model had already been validated against experimental biological data. 

## Biological Plausibility
While care was taken to compare the model outputs with known biological processes described in the literature and supported by experimental data, it is important to acknowledge that this type of comparison is inherently complex. Different models capture different aspects of the system, and even subtle variations in assumptions or parameter choices can lead to divergent behaviours. Different models may capture different aspects of the system, and even subtle variations in assumptions or parameter choices can lead to divergent behaviours. That said, these behaviours are still expected to remain within a plausible biological range—there is a limit to the extent of acceptable variation before a model becomes unrealistic. 

As such, the evaluation of biological plausibility should be interpreted with caution; it provides useful insight, but not definitive validation. The process of matching simulated outputs—such as concentration profiles and reaction kinetics—to literature values is valuable, yet inherently limited by the variability and uncertainty present in both modelling and experimental data.

Kinetic parameters used in the reactions were either sourced directly from the literature or inferred from experimental data where available. Where parameters were uncertain, sensitivity analyses were conducted to determine how kinetic rates impact model behaviour (see @sec-SA below). 

Furthermore, the model's ability to reproduce experimentally observed phenomena, such as CaMKII phosphorylation patterns, was critically assessed to confirm that the simulated system reflected realistic biological dynamics. Any discrepancies or deviations from expected biological behaviour were noted and considered in the context of the model's limitations. The results of these validation efforts, as well as the identified limitations, are discussed in more detail in the RESULTS-SECTION-REFERENCE.

The molecular concentrations used in this model fall within physiologically plausible ranges reported in the literature. For example, the initial release of 1000 $\mathrm{Ca^{2+}}$ ions corresponds to a concentration of 3.28~$\mu\text{M}$. Prior studies employing fluorescent $\mathrm{Ca^{2+}}$ indicators have shown resting intracellular $\mathrm{Ca^{2+}}$ concentrations ([$\mathrm{Ca^{2+}}$]$_i$) in the range of 0.05–0.1~$\mu\text{M}$, with increases up to 100-fold under stimulated conditions (Grienberger et al., 2012; Maravall et al., 2000). As such, the calcium input concentrations used in this model are consistent with the expected values under simulated conditions. Similarly, while the concentration of calmodulin (CaM) can vary widely in different studies, ranging from 0.1~$\mu\text{M}$ to 8~$\mu\text{M}$, with some reports extending up to 250~$\mu\text{M}$, the concentration of 0.98~$\mu\text{M}$ used in this model falls within these reported ranges. 

## Limitations

A more in depth discussion of the validity of chosen values and potential limitations is provided in @sec-validating-model. 

## Sensitivity Analysis for parameters{#sec-SA}
As discussed in @sec-intro-comp, computational models can serve as predictive tools to deepen our understanding of the mechanisms underlying observed biochemical processes. However, parameters such as rate constants, activation energies, thermodynamic constants, transport coefficients, etcetera, are rarely known with precision [REFERENCE]. Consequently, predictions are typically subject to uncertainty. That is why understanding how parameter variations influence outcomes is a crucial part of model development and validation.

As part of model development and validation, sensitivity analysis (SA) can be employed to determine which parameters the model is more or less responsive to. This technique focuses on  quantifying the impact of parameter changes on model predictions. SA aims to determine the influence of each input parameter on the model's output behaviour. In other words, SA is useful to assess how variations in input parameters, such as reaction propensities, rate constants, or initial concentrations, influence the system's outputs, which might include reaction trajectories, species concentrations over time, or the likelihood of certain reaction outcomes.

By quantifying the responsiveness of the model's outputs to variations in these parameters, SA enables researchers to prioritise the most impactful parameters for precise measurement or further investigation. This is especially valuable when studying chemical kinetics, where many parameters are difficult to measure directly and often carry inherent uncertainties [REFERENCE]. SA not only aids in parameter estimation but also guides experimental design by highlighting which aspects of the reaction system are most sensitive to changes, thereby improving the predictive accuracy of kinetic models such as the ones used in this PhD.

SA techniques can be broadly classified based on two key aspects: the analysis _scope_ and its _framework_. The scope of SA refers to whether the analysis focuses on small, local variations in input parameters or examines the global effect across a wider range of parameter values. Local sensitivity analysis typically investigates the effect of small perturbations in a single input parameter while holding others constant, often focusing on the immediate response of the model around a specific operating point. In contrast, global sensitivity analysis explores how changes in all relevant input parameters, over their entire range of possible values, influence the model's output, accounting for interactions between parameters and providing a more comprehensive view of model behaviour.

The framework aspect of SA refers to the approach used to model uncertainty (see @sec-how-do-we-model) in the system under study, and the method for sensitivity analysis will depend on whether the system is deterministic or probabilistic. In a deterministic sensitivity analysis framework, the relationship between inputs and outputs is precise and fixed, with no inherent randomness. 

Whereas a probabilistic (or stochastic) framework accounts for uncertainty by incorporating variability and randomness into the model, recognising that parameters may change within defined ranges or follow probability distributions. In a probabilistic model there are two sources of uncertainty: the parameter uncertainty and the uncertainty due to the stochasticity of the model. In a stochastic model, for any set of parameters, statistics derived from simulations have a distribution rather than being one value. A sensitivity analysis of a stochastic system typically considers how the estimated mean or median of that distribution varies as parameter(s) change.

- do i need to mention here limitation of runs of phd?
--
Sensitivity analysis is a technique to determine how the variation in the output of a model can be attributed to different inputs or parameters. This helps in identifying which parameters are most critical for the model's performance and which can be adjusted or estimated with less precision.

1. Determine the Range and Distribution of Each Parameter

- For each parameter, define a plausible range and, if possible, an assumed distribution (e.g., normal, uniform, etc.).
- These ranges should reflect the uncertainty or variability you expect in each parameter.

1. Sensitivity Analysis Method

- One-At-A-Time (OAT): Vary one parameter while keeping others constant. This helps assess individual parameter impact.

## Sanity checks:
As part of the validation process, sanity checks were implemented to ensure that the model behaved in a biologically reasonable manner across a wide range of conditions. These checks primary aim was to ensure that the model adhered to known biochemical constraints and reaction rules.

The sanity checks looked like looking for molecules that we know are not "allowed" to happen in the model according to the set reaction rules. 

The sanity checks were focused on ensuring that molecules which could not exist due to reaction constraints and biological principles, were not produced by the model. For instance, certain molecules, like cam_camkii_t306p, were expected to have a concentration of zero, or in other words, to not exist in the model, as the T306 phosphorylation site on CaMKII cannot be phosphorylated when the CAMKII subunit is bound to calmodulin.

- say that this is done through recording of observables in bngl file? and are commented with exact reasonings in the file itself too.

- CaMKII_CaM_Ca4_PP
- CaMKII_CaM_Ca4_T306P1
- CaMKII_CaM_closed
- CaMKII_CaM_unbound_closed_T286P1
- CaMKII_closed_complex 
- CaMKII_CaM_Ca4_PP_bound_NMDAR 
- CaMKII_CaM_Ca4_T306P1_bound_NMDAR

there are others that i havent done, how do i argue why yes or why not? 

this figure is a sanity test prob go in appendix ? ![alt text](40-results-figures/WT/subsets-of-camkii-t286p-cam-binding.png)

## Reproducibility and model robustness
_Write about the different ways in which CaMKII is instantiated in different runs._

## specs and reproducibility