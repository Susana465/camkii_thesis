# Validating model behaviour {#sec-validating-model}
Model validation is essential to ensure that computational simulations reliably reflect underlying biological mechanisms. In this work, the validation involved modular development of the model, comparison with experimental data, and assessment of both qualitative and quantitative accuracy. Each aspect of the model was tested in isolation before integration, and several complementary strategies were employed to evaluate the accuracy, robustness, and predictive capabilities of the system.

## Model description (may delete later)
As explained in @sec-intro-comp I use Monte Carlo algorithm simulations with the new MCell4 which combines the spatial simulation features of MCell3 [@kerr2008FAST] and the rule-based, network-free simulation (NFSim) framework of BioNetGen Language (BNGL). This integration of capabilities offers a flexible and robust tool that is well-suited for investigating the kinetics of complex reactions within the space of a dendritic spine. 

I model the interactions of various molecules released inside the cell, including $\mathrm{Ca^{2+}}$ , CaM, CaMKII, PP1, and NMDARs on the cell surface. I examine the binding dynamics of calcium to CaM and its subsequent interactions with CaMKII, focusing on the different states of CaMKII (open/closed, active/inactive) and the phosphorylation processes involved. The results [@sec-results] discuss the importance of CaMKII binding to NMDARs, as well as the regulatory role of CaMKII phosphorylation. 

The model was validated against biological results at various stages. First, the calcium release and subsequent binding to CaM were validated against [REFERENCES], testing the sequential binding of calcium. Next, to test for CaMKII activation, I assessed how much CaMKII flickered between active/open and inactive/closed states. Stefan et al. determined that the activation probability (in the absence of CaM and phosphorylation) is 0.002 (WRONG NUMBER? CHECK IN PAPER REF), so CaMKII's subunit flickering between open and closing was set with this parameter.

This flickering behavior should allow for CaM_Ca4 to bind to the open state, further stabilizing CaMKII, as observed in in vitro and in vivo studies [REFERENCES]. The stabilization of CaMKII in the open state by CaM binding is known as CaM trapping, and our model exhibits this behavior [FIGURE]. Additionally, CaMKII autophosphorylation at T286 and T306 is also modeled to showcase the regulatory functions of these sites.

The model uses a stochastic agent-based approach, where the program tracks only the reactions that occur between existing discrete molecules during the simulation (network-free simulation [119, 120]). A key aspect of this approach is that the number of different states present can be much smaller than the total number of possible states. Generally, stochastic simulations are preferred when the number of particles of a chemical species is small. When the assumption of continuous concentration fails due to limited populations of reactants in a small cellular environment, the ODE representation fails and stochastic simulations are particularly useful.


## Modularity
In order to validate model behaviour, it was constructed in a modular fashion, with each reaction or set of reactions added sequentially and tested independently. Modular testing is a key strategy in model validation that, in this case, involved building the model in discrete, self-contained units (or modules). Each module corresponds to a specific biochemical rule, where each one was added one by one and tested to see if it reproduced biologically beliavable results. By structuring the model in this way, it becomes possible to test and validate individual components independently before integrating them into the full system. This modular approach ensures that the model is built gradually, allowing for careful validation of each new set of reactions before proceeding to more complex processes. This stepwise approach minimises the risk of introducing compounded errors when combining multiple reactions or pathways.

For example, I initially incorporated reactions involving calcium binding to calmodulin and validated this by comparing its output against a previously developed and validated model described in the dissertation [reference]. This comparison served as an internal benchmark, as the original model had already been validated against experimental biological data. 

Moreover, the modular design facilitates future updates and refinements. As new experimental data becomes available or as the biological understanding of the system evolves, individual modules can be updated or expanded without the need to revalidate the entire model. This flexibility is a key advantage in a building long-term, adaptable computational model.

## Biological Plausibility
Furthermore, to examine whether the model produced biologically plausible behaviour, the results were compared to known biological processes described in the literature or seen in experimental data. Likewise, simulation outputs such as concentration profiles and reaction kinetics were directly compared to values reported in the literature.

Kinetic parameters used in the reactions were either sourced directly from the literature or inferred from experimental data where available. Where parameters were uncertain, sensitivity analyses were conducted to determine how kinetic rates impact model behaviour (see @sec-SA below). 

Furthermore, the model's ability to reproduce experimentally observed phenomena, such as CaMKII phosphorylation patterns, was critically assessed to confirm that the simulated system reflected realistic biological dynamics. Any discrepancies or deviations from expected biological behaviour were noted and considered in the context of the model's limitations. The results of these validation efforts, as well as the identified limitations, are discussed in more detail in the RESULTS-SECTION-REFERENCE.

- prob need to mention and not sure if discuss here the models i took params from? or not?

discuss each molecule concetation validity? 
The molecular concentrations used in this model fall within physiologically plausible ranges reported in the literature. For example, the initial release of 1000 $\mathrm{Ca^{2+}}$ ions corresponds to a concentration of 3.28~$\mu\text{M}$. Prior studies employing fluorescent $\mathrm{Ca^{2+}}$ indicators have shown resting intracellular $\mathrm{Ca^{2+}}$ concentrations ([$\mathrm{Ca^{2+}}$]$_i$) in the range of 0.05â€“0.1~$\mu\text{M}$, with increases up to 100-fold under stimulated conditions (Grienberger et al., 2012; Maravall et al., 2000). As such, the calcium input concentrations used in this model are consistent with the expected values under simulated conditions. Similarly, while the concentration of calmodulin (CaM) can vary widely in different studies, ranging from 0.1~$\mu\text{M}$ to 8~$\mu\text{M}$, with some reports extending up to 250~$\mu\text{M}$, the concentration of 0.98~$\mu\text{M}$ used in this model falls within these reported ranges. A more in depth discussion of the validity of chosen values and potential limitations is provided in @sec-sec-validating-model. 
iooooooooooo8loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo

## Sensitivity Analysis for parameters{#sec-SA}

As discussed in @sec-intro-comp, computational models can serve as predictive tools to deepen our understanding of the mechanisms underlying observed biochemical processes. However, parameters such as rate constants, activation energies, thermodynamic constants, transport coefficients, etcetera, are rarely known with precision [REFERENCE]. Consequently, predictions are typically subject to uncertainty. That is why understanding how parameter variations influence outcomes is a crucial part of model development and validation.

As part of model development and validation, sensitivity analysis (SA) can be employed to determine which parameters the model is more or less responsive to. This technique focuses on  quantifying the impact of parameter changes on model predictions. SA aims to determine the influence of each input parameter on the model's output behaviour. In other words, SA is useful to assess how variations in input parameters, such as reaction propensities, rate constants, or initial concentrations, influence the system's outputs, which might include reaction trajectories, species concentrations over time, or the likelihood of certain reaction outcomes.

By quantifying the responsiveness of the model's outputs to variations in these parameters, SA enables researchers to prioritise the most impactful parameters for precise measurement or further investigation. This is especially valuable when studying chemical kinetics, where many parameters are difficult to measure directly and often carry inherent uncertainties [REFERENCE]. SA not only aids in parameter estimation but also guides experimental design by highlighting which aspects of the reaction system are most sensitive to changes, thereby improving the predictive accuracy of kinetic models such as the ones used in this PhD.

SA techniques can be broadly classified based on two key aspects: the analysis _scope_ and its _framework_. The scope of SA refers to whether the analysis focuses on small, local variations in input parameters or examines the global effect across a wider range of parameter values. Local sensitivity analysis typically investigates the effect of small perturbations in a single input parameter while holding others constant, often focusing on the immediate response of the model around a specific operating point. In contrast, global sensitivity analysis explores how changes in all relevant input parameters, over their entire range of possible values, influence the model's output, accounting for interactions between parameters and providing a more comprehensive view of model behaviour.

The framework aspect of SA refers to the approach used to model uncertainty (see @sec-how-do-we-model) in the system under study, and the method for sensitivity analysis will depend on whether the system is deterministic or probabilistic. In a deterministic sensitivity analysis framework, the relationship between inputs and outputs is precise and fixed, with no inherent randomness. 

Whereas a probabilistic (or stochastic) framework accounts for uncertainty by incorporating variability and randomness into the model, recognising that parameters may change within defined ranges or follow probability distributions. In a probabilistic model there are two sources of uncertainty: the parameter uncertainty and the uncertainty due to the stochasticity of the model. In a stochastic model, for any set of parameters, statistics derived from simulations have a distribution rather than being one value. A sensitivity analysis of a stochastic system typically considers how the estimated mean or median of that distribution varies as parameter(s) change.

- do i need to mention here limitation of runs of phd?
--
Sensitivity analysis is a technique to determine how the variation in the output of a model can be attributed to different inputs or parameters. This helps in identifying which parameters are most critical for the model's performance and which can be adjusted or estimated with less precision.

1. Determine the Range and Distribution of Each Parameter

- For each parameter, define a plausible range and, if possible, an assumed distribution (e.g., normal, uniform, etc.).
- These ranges should reflect the uncertainty or variability you expect in each parameter.

1. Sensitivity Analysis Method

- One-At-A-Time (OAT): Vary one parameter while keeping others constant. This helps assess individual parameter impact.

## Sanity checks:
As part of the validation process, sanity checks were implemented to ensure that the model behaved in a biologically reasonable manner across a wide range of conditions. These checks primary aim was to ensure that the model adhered to known biochemical constraints and reaction rules.

The sanity checks looked like looking for molecules that we know are not "allowed" to happen in the model according to the set reaction rules. 

The sanity checks were focused on ensuring that molecules which could not exist due to reaction constraints and biological principles, were not produced by the model. For instance, certain molecules, like cam_camkii_t306p, were expected to have a concentration of zero, or in other words, to not exist in the model, as the T306 phosphorylation site on CaMKII cannot be phosphorylated when the CAMKII subunit is bound to calmodulin.

- say that this is done through recording of observables in bngl file? and are commented with exact reasonings in the file itself too.

- CaMKII_CaM_Ca4_PP
- CaMKII_CaM_Ca4_T306P1
- CaMKII_CaM_closed
- CaMKII_CaM_unbound_closed_T286P1
- CaMKII_closed_complex 
- CaMKII_CaM_Ca4_PP_bound_NMDAR 
- CaMKII_CaM_Ca4_T306P1_bound_NMDAR

there are others that i havent done, how do i argue why yes or why not? 

this figure is a sanity test prob go in appendix ? ![alt text](40-results-figures/WT/subsets-of-camkii-t286p-cam-binding.png)

## Reproducibility and model robustness
_Write about the different ways in which CaMKII is instantiated in different runs._

## specs and reproducibility